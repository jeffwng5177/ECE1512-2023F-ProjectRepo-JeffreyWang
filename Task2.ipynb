{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffwng5177/ECE1512-2023F-ProjectRepo-JeffreyWang/blob/main/Task2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7hrw7cpC4al"
      },
      "source": [
        "Project B MHIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3_QJntSn_GU",
        "outputId": "43994f1f-4465-4f80-971b-13893e2a49f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import os\n",
        "os.chdir(\"/content/gdrive/My Drive/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tsa1OwDC2Uz"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Flatten\n",
        "from keras import regularizers\n",
        "import keras.backend as K\n",
        "from keras.models import load_model\n",
        "from tensorflow.core.util import event_pb2\n",
        "from tensorflow.python.lib.io import tf_record\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.metrics as metrics\n",
        "import cv2\n",
        "\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbZgalrNe9f3"
      },
      "source": [
        "Generate Test/Train batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pdk47IxDgAZ",
        "outputId": "91aa12ef-5c86-4fce-9d60-4cbb7070f00c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2192 images belonging to 2 classes.\n",
            "Found 986 images belonging to 2 classes.\n",
            "<keras.preprocessing.image.DirectoryIterator object at 0x7fbbbf4c3190>\n",
            "<keras.preprocessing.image.DirectoryIterator object at 0x7fbbc0f14a90>\n"
          ]
        }
      ],
      "source": [
        "train_dir = '/content/gdrive/My Drive/mhist_dataset/images/train' #you should change to your directory\n",
        "test_dir = '/content/gdrive/My Drive/mhist_dataset/images/test' #you should change to your directory\n",
        "#train_dir = 'E:/UofTCourse/ECE1512/Assignment3/Project_B_Supp/Project_B_Supp/mhist_dataset/images/train' #you should change to your directory\n",
        "#test_dir = 'E:/UofTCourse/ECE1512/Assignment3/Project_B_Supp/Project_B_Supp/mhist_dataset/images/test' #you should change to your directory\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "class_mode='categorical',\n",
        "interpolation='bilinear',\n",
        "target_size=(224, 224),\n",
        "batch_size=32,\n",
        "shuffle=True)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(test_dir,\n",
        "class_mode='categorical',\n",
        "interpolation='bilinear',\n",
        "target_size=(224, 224),\n",
        "batch_size=32,\n",
        "#shuffle=False)\n",
        "shuffle=True)\n",
        "print(test_generator)\n",
        "print(train_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHnkRltakISc"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = (224,224)\n",
        "IMG_SHAPE = IMG_SIZE + (3,)\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 10\n",
        "NUM_CLASSES = 2\n",
        "TRAIN_BATCHES_NUM = int(np.floor(2176/BATCH_SIZE))\n",
        "TEST_BATCHES_NUM  = int(np.floor(976/BATCH_SIZE))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augmentation"
      ],
      "metadata": {
        "id": "1JxtS5WEsuK8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYEKT7UREkpk"
      },
      "outputs": [],
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build and train teacher model"
      ],
      "metadata": {
        "id": "BQzM9dsGtDBE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Teacher Model"
      ],
      "metadata": {
        "id": "rXeT58ZksyTF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTDSfbyTEkpm",
        "outputId": "9abcbbc8-07b6-4dcf-df44-ee72f742e4fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94674944/94668760 [==============================] - 1s 0us/step\n",
            "94683136/94668760 [==============================] - 1s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " sequential (Sequential)     (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " tf.math.truediv (TFOpLambda  (None, 224, 224, 3)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " tf.math.subtract (TFOpLambd  (None, 224, 224, 3)      0         \n",
            " a)                                                              \n",
            "                                                                 \n",
            " resnet50v2 (Functional)     (None, 7, 7, 2048)        23564800  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 2048)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 4098      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,568,898\n",
            "Trainable params: 4,098\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "base_model_teacher = ResNet50V2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
        "base_model_teacher.trainable = False\n",
        "\n",
        "prediction_layer = tf.keras.layers.Dense(2)\n",
        "\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "\n",
        "inputs_t = tf.keras.Input(shape=(224, 224, 3))\n",
        "x_t = data_augmentation(inputs_t)\n",
        "x_t = tf.keras.applications.resnet_v2.preprocess_input(x_t)\n",
        "x_t = base_model_teacher(x_t)\n",
        "x_t = global_average_layer(x_t)\n",
        "outputs_t = prediction_layer(x_t)\n",
        "teacher_model = tf.keras.Model(inputs_t, outputs_t)\n",
        "teacher_model.summary()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f-OtzxPihRD"
      },
      "source": [
        "Teacher loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dc0sgBHfEkpp"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def compute_teacher_loss(images, labels):\n",
        "  \"\"\"Compute subclass knowledge distillation teacher loss for given images\n",
        "     and labels.\n",
        "\n",
        "  Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Scalar loss Tensor.\n",
        "  \"\"\"\n",
        "  subclass_logits = teacher_model(images, training=True)\n",
        "  #print('a')\n",
        "  #print(subclass_logits.shape)\n",
        "  #print(labels.shape)\n",
        "  # Compute cross-entropy loss for subclasses.\n",
        "\n",
        "  # your code start from here for step 3\n",
        "  cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "  cross_entropy_loss_value = cce(labels, subclass_logits)\n",
        "  #print(cross_entropy_loss_value)\n",
        "  return cross_entropy_loss_value\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvUw-wAzEkpr"
      },
      "source": [
        "Train and evaluation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyIEaidcEkps"
      },
      "outputs": [],
      "source": [
        "\n",
        "def compute_num_correct(model, images, labels):\n",
        "  \"\"\"Compute number of correctly classified images in a batch.\n",
        "\n",
        "  Args:\n",
        "    model: Instance of tf.keras.Model.\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Number of correctly classified images.\n",
        "  \"\"\"\n",
        "  class_logits = model(images, training=False)\n",
        "  return tf.reduce_sum(\n",
        "      tf.cast(tf.math.equal(tf.argmax(class_logits, -1), tf.argmax(labels, -1)),\n",
        "              tf.float32)), tf.argmax(class_logits, -1), tf.argmax(labels, -1)\n",
        "\n",
        "\n",
        "def train_and_evaluate(model, compute_loss_fn, epochs, lr):\n",
        "  \"\"\"Perform training and evaluation for a given model.\n",
        "\n",
        "  Args:\n",
        "    model: Instance of tf.keras.Model.\n",
        "    compute_loss_fn: A function that computes the training loss given the\n",
        "      images, and labels.\n",
        "  \"\"\"\n",
        "\n",
        "  # your code start from here for step 4\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "\n",
        "  for epoch in range(1, epochs + 1):\n",
        "    # Run training.\n",
        "    print('Epoch {}: '.format(epoch), end='')\n",
        "\n",
        "    for batch in range(TRAIN_BATCHES_NUM):\n",
        "      images, labels = train_generator.next()\n",
        "\n",
        "      with tf.GradientTape() as tape:\n",
        "         # your code start from here for step 4\n",
        "        loss_value = compute_loss_fn(images, labels)\n",
        "\n",
        "      grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "      #print(model.trainable_variables)\n",
        "      #print(\"grads\")\n",
        "      #print(np.array(grads).shape)\n",
        "      #print(\"model.trainable_variables\")\n",
        "      #print(np.array(model.trainable_variables).shape)\n",
        "\n",
        "    # Run evaluation.\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "\n",
        "    for batch in range(TEST_BATCHES_NUM):\n",
        "      images, labels = test_generator.next()\n",
        "      # your code start from here for step 4\n",
        "\n",
        "      label_together = np.array(compute_num_correct(model, images, labels))\n",
        "      label_real = label_together[2]\n",
        "      label_pred = label_together[1]\n",
        "      #print(\"label_predicted\")\n",
        "      #print(label_pred)\n",
        "      #print(\"label_real\")\n",
        "      #print(label_real)\n",
        "      sum_same = np.array((label_real == label_pred),int)\n",
        "\n",
        "      num_total += labels.shape[0]\n",
        "      num_correct += tf.reduce_sum(sum_same)\n",
        "      #print('num_correct')\n",
        "      #print(num_correct)\n",
        "      #print('num_correct')\n",
        "      #print(num_total)\n",
        "    print(\"Class_accuracy: \" + '{:.2f}%'.format(\n",
        "        num_correct / num_total * 100))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlH9yjFPufrW"
      },
      "source": [
        "Feature Extraction Teacher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBLqI6kYEkpu",
        "outputId": "c0b9c4c0-3f95-4068-d1b7-5ff899157e0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class_accuracy: 63.54%\n",
            "Epoch 2: Class_accuracy: 63.10%\n",
            "Epoch 3: Class_accuracy: 63.21%\n",
            "Epoch 4: Class_accuracy: 64.05%\n",
            "Epoch 5: Class_accuracy: 64.78%\n",
            "Epoch 6: Class_accuracy: 62.05%\n",
            "Epoch 7: Class_accuracy: 63.21%\n",
            "Epoch 8: Class_accuracy: 64.47%\n",
            "Epoch 9: Class_accuracy: 64.36%\n",
            "Epoch 10: Class_accuracy: 62.58%\n"
          ]
        }
      ],
      "source": [
        "train_and_evaluate(teacher_model, compute_teacher_loss,epochs=10,lr=0.0001)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine Tuning Teacher"
      ],
      "metadata": {
        "id": "idoVdbxDs_bF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvDpLNg0Ekpv",
        "outputId": "8c6b08d8-fcfe-42ef-d5da-ca7e6909d548"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of layers in the base model:  190\n"
          ]
        }
      ],
      "source": [
        "base_model_teacher.trainable = True\n",
        "\n",
        "# Let's take a look to see how many layers are in the base model\n",
        "print(\"Number of layers in the base model: \", len(base_model_teacher.layers))\n",
        "\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 0\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in base_model_teacher.layers[:fine_tune_at]:\n",
        "  layer.trainable =  False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7SCP0tREkpv"
      },
      "outputs": [],
      "source": [
        "train_and_evaluate(teacher_model, compute_teacher_loss,epochs=25,lr=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XeMj2qDfYrXR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5241364f-c4ad-43ea-fe22-ff71203c3199"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: teacher_model/assets\n"
          ]
        }
      ],
      "source": [
        "teacher_model.save(\"teacher_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOjCY6qjlEOr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ba19f27-a284-4e05-a39a-2c556685109d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " sequential_1 (Sequential)   (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " tf.math.truediv_2 (TFOpLamb  (None, 224, 224, 3)      0         \n",
            " da)                                                             \n",
            "                                                                 \n",
            " tf.math.subtract_2 (TFOpLam  (None, 224, 224, 3)      0         \n",
            " bda)                                                            \n",
            "                                                                 \n",
            " resnet50v2 (Functional)     (None, 7, 7, 2048)        23564800  \n",
            "                                                                 \n",
            " global_average_pooling2d_2   (None, 2048)             0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 4098      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,568,898\n",
            "Trainable params: 23,422,466\n",
            "Non-trainable params: 146,432\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#teacher_model = keras.models.load_model(\"teacher_model\")\n",
        "teacher_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KpTO8__YtNQ"
      },
      "source": [
        "# Build and train Student Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwLAbliFxYsT"
      },
      "source": [
        "Student Model with KD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUIpjioiEIeP",
        "outputId": "bf68cde9-ce1c-4cb8-8d54-a2e46d5284f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n",
            "9420800/9406464 [==============================] - 0s 0us/step\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " sequential (Sequential)     (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " tf.math.truediv_1 (TFOpLamb  (None, 224, 224, 3)      0         \n",
            " da)                                                             \n",
            "                                                                 \n",
            " tf.math.subtract_1 (TFOpLam  (None, 224, 224, 3)      0         \n",
            " bda)                                                            \n",
            "                                                                 \n",
            " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " global_average_pooling2d_1   (None, 1280)             0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                81984     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,340,098\n",
            "Trainable params: 82,114\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "base_model_student1 = MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
        "base_model_student1.trainable = False\n",
        "\n",
        "dense1_layer1 = tf.keras.layers.Dense(64,activation='relu')\n",
        "drop_out1_layer1 = tf.keras.layers.Dropout(rate=0.2)\n",
        "drop_out2_layer1 = tf.keras.layers.Dropout(rate=0.2)\n",
        "\n",
        "prediction_layer1 = tf.keras.layers.Dense(2)\n",
        "\n",
        "global_average_layer1 = tf.keras.layers.GlobalAveragePooling2D()\n",
        "\n",
        "inputs_s1 = tf.keras.Input(shape=(224, 224, 3))\n",
        "x_s1 = data_augmentation(inputs_s1)\n",
        "x_s1 = tf.keras.applications.mobilenet_v2.preprocess_input(x_s1)\n",
        "#x_s1 = tf.keras.applications.resnet_v2.preprocess_input(x_s1)\n",
        "x_s1 = base_model_student1(x_s1)\n",
        "x_s1 = global_average_layer1(x_s1)\n",
        "x_s1 = drop_out1_layer1(x_s1)\n",
        "x_s1 = dense1_layer1(x_s1)\n",
        "x_s1 = drop_out2_layer1(x_s1)\n",
        "\n",
        "outputs_s1 = prediction_layer1(x_s1)\n",
        "student_model = tf.keras.Model(inputs_s1, outputs_s1)\n",
        "student_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSIfUYt-xg5j"
      },
      "source": [
        "Student Model without KD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gccGsmXc4K7K",
        "outputId": "66d66181-8631-424e-8290-bba79a77b228"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " sequential (Sequential)     (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " tf.math.truediv_2 (TFOpLamb  (None, 224, 224, 3)      0         \n",
            " da)                                                             \n",
            "                                                                 \n",
            " tf.math.subtract_2 (TFOpLam  (None, 224, 224, 3)      0         \n",
            " bda)                                                            \n",
            "                                                                 \n",
            " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " global_average_pooling2d (G  multiple                 0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                81984     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,340,098\n",
            "Trainable params: 82,114\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "base_model_student2 = MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
        "#base_model_student2 = ResNet50V2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
        "base_model_student2.trainable = False\n",
        "\n",
        "prediction_layer2 = tf.keras.layers.Dense(2)\n",
        "\n",
        "global_average_layer2 = tf.keras.layers.GlobalAveragePooling2D()\n",
        "\n",
        "dense1_layer2 = tf.keras.layers.Dense(64,activation='relu')\n",
        "drop_out1_layer2 = tf.keras.layers.Dropout(rate=0.2)\n",
        "drop_out2_layer2 = tf.keras.layers.Dropout(rate=0.2)\n",
        "\n",
        "inputs_s2 = tf.keras.Input(shape=(224, 224, 3))\n",
        "x_s2 = data_augmentation(inputs_s2)\n",
        "x_s2 = tf.keras.applications.mobilenet_v2.preprocess_input(x_s2)\n",
        "#x_s2 = tf.keras.applications.resnet_v2.preprocess_input(x_s2)\n",
        "x_s2 = base_model_student2(x_s2)\n",
        "x_s2 = global_average_layer(x_s2)\n",
        "\n",
        "x_s2 = drop_out1_layer2(x_s2)\n",
        "x_s2 = dense1_layer2(x_s2)\n",
        "x_s2 = drop_out2_layer2(x_s2)\n",
        "\n",
        "outputs_s2 = prediction_layer2(x_s2)\n",
        "student_model_no_distillation = tf.keras.Model(inputs_s2, outputs_s2)\n",
        "student_model_no_distillation.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Z2-1u8txkM9"
      },
      "source": [
        "State of Art Student Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_NdS1ifMIXp",
        "outputId": "b95ae15e-2d35-4011-edd1-0d94b3f1807b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " sequential (Sequential)     (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " tf.math.truediv_3 (TFOpLamb  (None, 224, 224, 3)      0         \n",
            " da)                                                             \n",
            "                                                                 \n",
            " tf.math.subtract_3 (TFOpLam  (None, 224, 224, 3)      0         \n",
            " bda)                                                            \n",
            "                                                                 \n",
            " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " global_average_pooling2d (G  multiple                 0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                81984     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,340,098\n",
            "Trainable params: 82,114\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "base_model_student3 = MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
        "base_model_student3.trainable = False\n",
        "\n",
        "prediction_layer3 = tf.keras.layers.Dense(2)\n",
        "\n",
        "global_average_layer3 = tf.keras.layers.GlobalAveragePooling2D()\n",
        "\n",
        "dense1_layer3 = tf.keras.layers.Dense(64,activation='relu')\n",
        "drop_out1_layer3 = tf.keras.layers.Dropout(rate=0.2)\n",
        "drop_out2_layer3 = tf.keras.layers.Dropout(rate=0.2)\n",
        "\n",
        "inputs_s3 = tf.keras.Input(shape=(224, 224, 3))\n",
        "x_s3 = data_augmentation(inputs_s3)\n",
        "x_s3 = tf.keras.applications.mobilenet_v2.preprocess_input(x_s3)\n",
        "x_s3 = base_model_student2(x_s3)\n",
        "x_s3 = global_average_layer(x_s3)\n",
        "\n",
        "x_s3 = drop_out1_layer2(x_s3)\n",
        "x_s3 = dense1_layer2(x_s3)\n",
        "x_s3 = drop_out2_layer2(x_s3)\n",
        "\n",
        "outputs_s3 = prediction_layer2(x_s3)\n",
        "student_model_improved = tf.keras.Model(inputs_s3, outputs_s3)\n",
        "student_model_improved.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35WJgbCEipMv"
      },
      "source": [
        "Student loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDKia4gPQMIr"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters for distillation (need to be tuned).\n",
        "ALPHA = 0.5 # task balance between cross-entropy and distillation loss\n",
        "DISTILLATION_TEMPERATURE = 64. #temperature hyperparameter 1,2,4,16,32,64\n",
        "\n",
        "def distillation_loss(teacher_logits: tf.Tensor, student_logits: tf.Tensor,\n",
        "                      temperature: tf.Tensor):\n",
        "  \"\"\"Compute distillation loss.\n",
        "\n",
        "  This function computes cross entropy between softened logits and softened\n",
        "  targets. The resulting loss is scaled by the squared temperature so that\n",
        "  the gradient magnitude remains approximately constant as the temperature is\n",
        "  changed. For reference, see Hinton et al., 2014, \"Distilling the knowledge in\n",
        "  a neural network.\"\n",
        "\n",
        "  Args:\n",
        "    teacher_logits: A Tensor of logits provided by the teacher.\n",
        "    student_logits: A Tensor of logits provided by the student, of the same\n",
        "      shape as `teacher_logits`.\n",
        "    temperature: Temperature to use for distillation.\n",
        "\n",
        "  Returns:\n",
        "    A scalar Tensor containing the distillation loss.\n",
        "  \"\"\"\n",
        " # your code start from here for step 3\n",
        "  soft_targets = keras.backend.softmax(teacher_logits/temperature) #softmax of teacher logits\n",
        "\n",
        "  return tf.reduce_mean(\n",
        "      tf.nn.softmax_cross_entropy_with_logits(\n",
        "          soft_targets, student_logits / temperature)) * temperature ** 2\n",
        "\n",
        "def compute_student_loss(images, labels):\n",
        "  \"\"\"Compute subclass knowledge distillation student loss for given images\n",
        "     and labels.\n",
        "\n",
        "  Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Scalar loss Tensor.\n",
        "  \"\"\"\n",
        "  subclass_logits = student_model(images, training=True)\n",
        "\n",
        "\n",
        "\n",
        "  teacher_subclass_logits = teacher_model(images, training=False)\n",
        "  distillation_loss_value = distillation_loss(teacher_subclass_logits, subclass_logits,\n",
        "                      DISTILLATION_TEMPERATURE)\n",
        "\n",
        "  #cross_entropy_loss_value = keras.backend.softmax(student_subclass_logits)\n",
        "  cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "  cross_entropy_loss_value = cce(labels, subclass_logits)\n",
        "  return ALPHA * cross_entropy_loss_value + (1- ALPHA) * distillation_loss_value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oIK_I4jCO-j"
      },
      "source": [
        "Student Loss Function without KD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52eLob7yCJm8"
      },
      "outputs": [],
      "source": [
        "def compute_plain_cross_entropy_loss(images, labels):\n",
        "\n",
        "  subclass_logits = student_model_no_distillation(images, training=True)\n",
        "  cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "  cross_entropy_loss_value = cce(labels, subclass_logits)\n",
        "  return cross_entropy_loss_value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2zK0FZljBLt"
      },
      "source": [
        "Train and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtoLbp8uQ4Vl"
      },
      "outputs": [],
      "source": [
        "\n",
        "def compute_num_correct(model, images, labels):\n",
        "  \"\"\"Compute number of correctly classified images in a batch.\n",
        "\n",
        "  Args:\n",
        "    model: Instance of tf.keras.Model.\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Number of correctly classified images.\n",
        "  \"\"\"\n",
        "  class_logits = model(images, training=True)\n",
        "  #print('Compute num correct')\n",
        "  #tf.print(class_logits)\n",
        "  #tf.print(tf.argmax(class_logits, -1))\n",
        "  #tf.print(tf.argmax(labels, -1))\n",
        "  return tf.reduce_sum(\n",
        "      tf.cast(tf.math.equal(tf.argmax(class_logits, -1), tf.argmax(labels, -1)),\n",
        "              tf.float32)), tf.argmax(class_logits, -1), tf.argmax(labels, -1)\n",
        "\n",
        "\n",
        "def train_and_evaluate(model, compute_loss_fn, epochs, lr):\n",
        "  \"\"\"Perform training and evaluation for a given model.\n",
        "\n",
        "  Args:\n",
        "    model: Instance of tf.keras.Model.\n",
        "    compute_loss_fn: A function that computes the training loss given the\n",
        "      images, and labels.\n",
        "  \"\"\"\n",
        "\n",
        "  # your code start from here for step 4\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "\n",
        "  for epoch in range(1, epochs + 1):\n",
        "    # Run training.\n",
        "    print('Epoch {}: '.format(epoch), end='')\n",
        "\n",
        "    for batch in range(TRAIN_BATCHES_NUM):\n",
        "      images, labels = train_generator.next()\n",
        "\n",
        "      with tf.GradientTape() as tape:\n",
        "         # your code start from here for step 4\n",
        "        loss_value = compute_loss_fn(images, labels)\n",
        "\n",
        "      grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "      #print(model.trainable_variables)\n",
        "      #print(\"grads\")\n",
        "      #print(np.array(grads).shape)\n",
        "      #print(\"model.trainable_variables\")\n",
        "      #print(np.array(model.trainable_variables).shape)\n",
        "\n",
        "    # Run evaluation.\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "\n",
        "    for batch in range(TEST_BATCHES_NUM):\n",
        "      images, labels = test_generator.next()\n",
        "      # your code start from here for step 4\n",
        "\n",
        "      label_together = np.array(compute_num_correct(model, images, labels))\n",
        "      label_real = label_together[2]\n",
        "      label_pred = label_together[1]\n",
        "      #print(\"label_predicted\")\n",
        "      #print(label_pred)\n",
        "      #print(\"label_real\")\n",
        "      #print(label_real)\n",
        "      sum_same = np.array((label_real == label_pred),int)\n",
        "\n",
        "      num_total += labels.shape[0]\n",
        "      #num_correct += tf.reduce_sum(sum_same)\n",
        "      num_correct += label_together[0]\n",
        "      #print('num_correct')\n",
        "      #print(num_correct)\n",
        "      #print('num_correct')\n",
        "      #print(num_total)\n",
        "    print(\"Class_accuracy: \" + '{:.2f}%'.format(\n",
        "        num_correct / num_total * 100))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGBfzXEtCafW"
      },
      "source": [
        "Feature Extraction Student without KD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okCxBLJjK9Xy",
        "outputId": "286534e6-969e-43b5-f900-fedbe997639a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of layers in the base model:  190\n"
          ]
        }
      ],
      "source": [
        "base_model_student2.trainable = True\n",
        "\n",
        "# Let's take a look to see how many layers are in the base model\n",
        "print(\"Number of layers in the base model: \", len(base_model_teacher.layers))\n",
        "\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 100\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in base_model_student2.layers[:fine_tune_at]:\n",
        "  layer.trainable =  False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcrh-NnM_F6Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62b9e2ba-a299-44a3-8d32-23ac9c5503c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:62: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class_accuracy: 65.30%\n",
            "Epoch 2: Class_accuracy: 63.84%\n",
            "Epoch 3: Class_accuracy: 62.58%\n",
            "Epoch 4: Class_accuracy: 66.67%\n",
            "Epoch 5: Class_accuracy: 71.80%\n",
            "Epoch 6: Class_accuracy: 67.19%\n",
            "Epoch 7: Class_accuracy: 69.29%\n",
            "Epoch 8: Class_accuracy: 68.66%\n",
            "Epoch 9: Class_accuracy: 69.08%\n",
            "Epoch 10: Class_accuracy: 71.17%\n"
          ]
        }
      ],
      "source": [
        "train_and_evaluate(student_model_no_distillation, compute_plain_cross_entropy_loss,epochs=10,lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AZDPf90_kFT"
      },
      "source": [
        "Fine tuning Student (without KD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnpWCI4G_P7G",
        "outputId": "785d419f-ba55-436e-d5fc-2ffb7d1fd64a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of layers in the base model:  190\n"
          ]
        }
      ],
      "source": [
        "base_model_student2.trainable = True\n",
        "\n",
        "# Let's take a look to see how many layers are in the base model\n",
        "print(\"Number of layers in the base model: \", len(base_model_teacher.layers))\n",
        "\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 0\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in base_model_student2.layers[:fine_tune_at]:\n",
        "  layer.trainable =  False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13nKm6yL_rWd"
      },
      "source": [
        "Train Student (without KD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GhYbyzaD_X5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1856ebb-5d75-4bbc-c63c-401dcec2c9dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:62: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class_accuracy: 68.45%\n",
            "Epoch 2: Class_accuracy: 72.22%\n",
            "Epoch 3: Class_accuracy: 77.57%\n",
            "Epoch 4: Class_accuracy: 80.71%\n",
            "Epoch 5: Class_accuracy: 80.71%\n",
            "Epoch 6: Class_accuracy: 80.50%\n",
            "Epoch 7: Class_accuracy: 80.71%\n",
            "Epoch 8: Class_accuracy: 80.19%\n",
            "Epoch 9: Class_accuracy: 81.66%\n",
            "Epoch 10: Class_accuracy: 82.18%\n",
            "Epoch 11: Class_accuracy: 83.44%\n",
            "Epoch 12: Class_accuracy: 82.91%\n",
            "Epoch 13: Class_accuracy: 82.18%\n",
            "Epoch 14: Class_accuracy: 81.55%\n",
            "Epoch 15: Class_accuracy: 81.56%\n",
            "Epoch 16: Class_accuracy: 82.81%\n",
            "Epoch 17: Class_accuracy: 81.76%\n",
            "Epoch 18: Class_accuracy: 81.87%\n",
            "Epoch 19: Class_accuracy: 81.34%\n",
            "Epoch 20: Class_accuracy: 82.49%\n",
            "Epoch 21: Class_accuracy: 82.70%\n",
            "Epoch 22: Class_accuracy: 81.87%\n",
            "Epoch 23: Class_accuracy: 81.24%\n",
            "Epoch 24: Class_accuracy: 84.17%\n",
            "Epoch 25: Class_accuracy: 82.08%\n"
          ]
        }
      ],
      "source": [
        "train_and_evaluate(student_model_no_distillation, compute_plain_cross_entropy_loss,epochs=25,lr=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srONTlOFvKtE"
      },
      "outputs": [],
      "source": [
        "#student_model_no_distillation.save(\"student_model_no_distillation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKKa_9TtzGAr"
      },
      "outputs": [],
      "source": [
        "#student_model_no_distillation = keras.models.load_model(\"student_model_no_distillation\")\n",
        "student_model_no_distillation.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ikVPGCkNOsW"
      },
      "source": [
        "Feature Extraction Student with KD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdbwkYXjNNfI",
        "outputId": "9318f7d9-b119-43eb-d0bd-8c8cffcb491d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:62: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class_accuracy: 64.15%\n",
            "Epoch 2: Class_accuracy: 62.47%\n",
            "Epoch 3: Class_accuracy: 63.42%\n",
            "Epoch 4: Class_accuracy: 63.52%\n",
            "Epoch 5: Class_accuracy: 63.31%\n",
            "Epoch 6: Class_accuracy: 62.47%\n",
            "Epoch 7: Class_accuracy: 62.89%\n",
            "Epoch 8: Class_accuracy: 65.62%\n",
            "Epoch 9: Class_accuracy: 63.52%\n",
            "Epoch 10: Class_accuracy: 62.16%\n"
          ]
        }
      ],
      "source": [
        "train_and_evaluate(student_model, compute_student_loss,epochs=10,lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHFEDyUJOqoc"
      },
      "source": [
        "Fine Tune Student (with KD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBPnbhijNjCM",
        "outputId": "910ea7ce-1fa1-4bb0-e028-6ea327d40790"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of layers in the base model:  190\n"
          ]
        }
      ],
      "source": [
        "base_model_student1.trainable = True\n",
        "\n",
        "# Let's take a look to see how many layers are in the base model\n",
        "print(\"Number of layers in the base model: \", len(base_model_teacher.layers))\n",
        "\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 0\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in base_model_student1.layers[:fine_tune_at]:\n",
        "  layer.trainable =  False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwltRxUcOoKY",
        "outputId": "4f3e072f-5fe4-44da-eb7a-516efb0235ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:62: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class_accuracy: 73.69%\n",
            "Epoch 2: Class_accuracy: 77.15%\n",
            "Epoch 3: Class_accuracy: 74.63%\n",
            "Epoch 4: Class_accuracy: 77.15%\n",
            "Epoch 5: Class_accuracy: 78.72%\n",
            "Epoch 6: Class_accuracy: 78.83%\n",
            "Epoch 7: Class_accuracy: 79.98%\n",
            "Epoch 8: Class_accuracy: 83.23%\n",
            "Epoch 9: Class_accuracy: 81.55%\n",
            "Epoch 10: Class_accuracy: 79.14%\n",
            "Epoch 11: Class_accuracy: 80.73%\n",
            "Epoch 12: Class_accuracy: 82.60%\n",
            "Epoch 13: Class_accuracy: 85.12%\n",
            "Epoch 14: Class_accuracy: 83.44%\n",
            "Epoch 15: Class_accuracy: 82.60%\n",
            "Epoch 16: Class_accuracy: 83.23%\n",
            "Epoch 17: Class_accuracy: 83.65%\n",
            "Epoch 18: Class_accuracy: 83.75%\n",
            "Epoch 19: Class_accuracy: 82.49%\n",
            "Epoch 20: Class_accuracy: 83.65%\n",
            "Epoch 21: Class_accuracy: 82.81%\n",
            "Epoch 22: Class_accuracy: 82.91%\n",
            "Epoch 23: Class_accuracy: 83.86%\n",
            "Epoch 24: Class_accuracy: 84.38%\n",
            "Epoch 25: Class_accuracy: 82.18%\n"
          ]
        }
      ],
      "source": [
        "train_and_evaluate(student_model, compute_student_loss,epochs=25,lr=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LJbOOh0MWkS",
        "outputId": "4eb2ed3c-179c-4cea-f181-fd014af669a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: student_model/assets\n"
          ]
        }
      ],
      "source": [
        "#student_model.save(\"student_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIrhgur57jYv",
        "outputId": "93a711c3-ecf0-4253-f348-cf995a23f285"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "#student_model = keras.models.load_model(\"student_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_7zkfW_J_pR"
      },
      "source": [
        "FLOPs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QGKJrIoF1Hm",
        "outputId": "b75bf90c-2d28-494e-a00e-fe0b7a5e4290"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras_flops\n",
            "  Downloading keras_flops-0.1.2-py3-none-any.whl (5.3 kB)\n",
            "Requirement already satisfied: tensorflow<3.0,>=2.2 in /usr/local/lib/python3.7/dist-packages (from keras_flops) (2.8.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.2->keras_flops) (3.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.2->keras_flops) (1.6.3)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.2->keras_flops) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.2->keras_flops) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.2->keras_flops) (0.24.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.2->keras_flops) (2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.2->keras_flops) (3.10.0.2)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.2->keras_flops) (1.21.5)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.2->keras_flops) (0.5.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.2->keras_flops) (13.0.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.2->keras_flops) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.2->keras_flops) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.2->keras_flops) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.2->keras_flops) (3.3.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.2->keras_flops) (1.44.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.2->keras_flops) (57.4.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.2->keras_flops) (2.8.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.2->keras_flops) (1.14.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.2->keras_flops) (3.17.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0,>=2.2->keras_flops) (1.0.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<3.0,>=2.2->keras_flops) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<3.0,>=2.2->keras_flops) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<3.0,>=2.2->keras_flops) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<3.0,>=2.2->keras_flops) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<3.0,>=2.2->keras_flops) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<3.0,>=2.2->keras_flops) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<3.0,>=2.2->keras_flops) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<3.0,>=2.2->keras_flops) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<3.0,>=2.2->keras_flops) (1.35.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<3.0,>=2.2->keras_flops) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<3.0,>=2.2->keras_flops) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<3.0,>=2.2->keras_flops) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<3.0,>=2.2->keras_flops) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<3.0,>=2.2->keras_flops) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<3.0,>=2.2->keras_flops) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<3.0,>=2.2->keras_flops) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<3.0,>=2.2->keras_flops) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<3.0,>=2.2->keras_flops) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<3.0,>=2.2->keras_flops) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<3.0,>=2.2->keras_flops) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<3.0,>=2.2->keras_flops) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly, keras-flops\n",
            "Successfully installed keras-flops-0.1.2 tf-estimator-nightly-2.8.0.dev2021122109\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "teacher model\n",
            "223633626304\n",
            "student model\n",
            "19618953216\n"
          ]
        }
      ],
      "source": [
        "# your code start from here for step 8\n",
        "!pip install keras_flops\n",
        "from keras_flops import get_flops\n",
        "flops = get_flops(teacher_model, batch_size=32)\n",
        "print('teacher model')\n",
        "print(flops)\n",
        "flops = get_flops(student_model, batch_size=32)\n",
        "print('student model')\n",
        "print(flops)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjVIxmIUPH7k"
      },
      "source": [
        "AUC teacher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7R1azuhOfvyh",
        "outputId": "459d02cc-1c53-4027-b1d0-038cac0cb5c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc\n",
            "0.80207914\n"
          ]
        }
      ],
      "source": [
        "auc = tf.keras.metrics.AUC(from_logits=True)\n",
        "auc.reset_state()\n",
        "\n",
        "for batch in range(TEST_BATCHES_NUM):\n",
        "  images, labels = test_generator.next()\n",
        "  # your code start from here for step 4\n",
        "\n",
        "  label_together = np.array(compute_num_correct(teacher_model, images, labels))\n",
        "  label_real = np.array(label_together[2],float)\n",
        "  label_pred = np.array(label_together[1],float)\n",
        "  auc.update_state(label_real,label_pred)\n",
        "\n",
        "print(\"auc\")\n",
        "print(auc.result().numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiB7uk0JP0yh"
      },
      "source": [
        "AUC Student no distillation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tGQfRRIzZAZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "951a5be3-0fcf-4daa-c5c1-d1df5c091644"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc\n",
            "0.77684546\n"
          ]
        }
      ],
      "source": [
        "\n",
        "auc = tf.keras.metrics.AUC(from_logits=True)\n",
        "auc.reset_state()\n",
        "\n",
        "\n",
        "for batch in range(TEST_BATCHES_NUM):\n",
        "  images, labels = test_generator.next()\n",
        "  # your code start from here for step 4\n",
        "  label_together = np.array(compute_num_correct(student_model_no_distillation, images, labels))\n",
        "  #print(compute_num_correct(student_model_no_distillation, images, labels))\n",
        "  label_real = np.array(label_together[2],float)\n",
        "  #print(label_real)\n",
        "  label_pred = np.array(label_together[1],float)\n",
        "  #print(label_pred)\n",
        "  auc.update_state(label_real,label_pred)\n",
        "print(\"auc\")\n",
        "print(auc.result().numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzzEXHkOPQfN"
      },
      "source": [
        "AUC Student with distillation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrQdN5EUF7NM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a041743-4a24-4088-858a-9e2975ef51d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc\n",
            "0.8104153\n"
          ]
        }
      ],
      "source": [
        "\n",
        "auc = tf.keras.metrics.AUC(from_logits=True)\n",
        "auc.reset_state()\n",
        "\n",
        "\n",
        "for batch in range(TEST_BATCHES_NUM):\n",
        "  images, labels = test_generator.next()\n",
        "  # your code start from here for step 4\n",
        "\n",
        "  label_together = np.array(compute_num_correct(student_model, images, labels))\n",
        "  label_real = np.array(label_together[2],float)\n",
        "  label_pred = np.array(label_together[1],float)\n",
        "  auc.update_state(label_real,label_pred)\n",
        "print(\"auc\")\n",
        "print(auc.result().numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61gC1hVl_NXd"
      },
      "source": [
        "State of Art KD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsU1rYWaDlGL"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.ops.math_ops import reduce_sum\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "# Hyperparameters for distillation (need to be tuned).\n",
        "ALPHA = 0.5 # task balance between cross-entropy and distillation loss\n",
        "DISTILLATION_TEMPERATURE = 0.1 #temperature hyperparameter #2\n",
        "batch_size = 32\n",
        "\n",
        "def distillation_loss_improved(teacher_logits: tf.Tensor, student_logits: tf.Tensor,\n",
        "                      temperature: tf.Tensor):\n",
        "\n",
        "  N = teacher_logits.shape[0]\n",
        "  #mask for correlated samples\n",
        "  mask = torch.ones((2*N, 2*N), dtype=bool)\n",
        "  mask.fill_diagonal_(0)\n",
        "  for i in range(N):\n",
        "      mask[i, N+i] = 0\n",
        "      mask[N+i, i] = 0\n",
        "\n",
        "  z = tf.concat([student_logits,teacher_logits],0)\n",
        "  z = np.array(z)\n",
        "  a1 = np.zeros([2*N,2*N,teacher_logits.shape[1]])\n",
        "  for i in range(2*N):\n",
        "    a1[i,:,:] = z\n",
        "  a2 = np.zeros([2*N,2*N,teacher_logits.shape[1]])\n",
        "  for i in range(2*N):\n",
        "    a2[:,i,:] = z\n",
        "  sim = tf.keras.losses.cosine_similarity(a1, a2,axis=2)\n",
        "  sim = np.array(sim)\n",
        "  sim = abs(sim)\n",
        "\n",
        "  negative_samples = np.array(sim[mask]).reshape(4*N*(N-1),1)\n",
        "  negative_samples = -negative_samples/temperature\n",
        "  negative_samples = 1 - 1/(tf.exp(negative_samples)+1)\n",
        "  negative_samples = tf.math.log(negative_samples)\n",
        "  negative_loss = tf.reduce_mean(negative_samples)\n",
        "  negative_loss = tf.cast(negative_loss, tf.float32)\n",
        "\n",
        "  positive_samples = tf.keras.losses.cosine_similarity(teacher_logits,student_logits)\n",
        "  positive_samples = -positive_samples/temperature\n",
        "  positive_samples = 1/(tf.exp(positive_samples)+1)\n",
        "  positive_samples = tf.math.log(positive_samples)\n",
        "  positive_loss = tf.reduce_mean(positive_samples)\n",
        "  positive_loss = tf.cast(positive_loss, tf.float32)\n",
        "  loss = positive_loss + negative_loss\n",
        "  return loss\n",
        "\n",
        "\n",
        "def compute_student_loss_new(images, labels):\n",
        "  \"\"\"Compute subclass knowledge distillation student loss for given images\n",
        "     and labels.\n",
        "\n",
        "  Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Scalar loss Tensor.\n",
        "  \"\"\"\n",
        "  student_subclass_logits = student_model(images, training=True)\n",
        "\n",
        "  # Compute subclass distillation loss between student subclass logits and\n",
        "  # softened teacher subclass targets probabilities.\n",
        "\n",
        "  # your code start from here for step 3\n",
        "\n",
        "  teacher_subclass_logits = teacher_model(images, training=False)\n",
        "  distillation_loss_value = distillation_loss_improved(teacher_subclass_logits, student_subclass_logits,\n",
        "                      DISTILLATION_TEMPERATURE)\n",
        "  #print(\"distillation_loss_value\")\n",
        "  #print(distillation_loss_value)\n",
        "\n",
        "  # Compute cross-entropy loss with hard targets.\n",
        "\n",
        "  # your code start from here for step 3\n",
        "\n",
        "  #cross_entropy_loss_value = keras.backend.softmax(student_subclass_logits)\n",
        "  cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "  cross_entropy_loss_value = cce(labels, student_subclass_logits)\n",
        "  #print(\"loss\")\n",
        "  #print(cross_entropy_loss_value)\n",
        "  #print(distillation_loss_value)\n",
        "  return ALPHA * cross_entropy_loss_value + (1- ALPHA) * distillation_loss_value\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRUldDS_PBAZ",
        "outputId": "64bd0fcb-056a-481b-bb04-d0ef698fd359"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_16 (InputLayer)       [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " sequential (Sequential)     (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " tf.math.truediv_7 (TFOpLamb  (None, 224, 224, 3)      0         \n",
            " da)                                                             \n",
            "                                                                 \n",
            " tf.math.subtract_7 (TFOpLam  (None, 224, 224, 3)      0         \n",
            " bda)                                                            \n",
            "                                                                 \n",
            " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " global_average_pooling2d_7   (None, 1280)             0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 64)                81984     \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,340,098\n",
            "Trainable params: 82,114\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "base_model_student1 = MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
        "#base_model_student1 = ResNet50V2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
        "base_model_student1.trainable = False\n",
        "\n",
        "dense1_layer1 = tf.keras.layers.Dense(64,activation='relu')\n",
        "drop_out1_layer1 = tf.keras.layers.Dropout(rate=0.2)\n",
        "drop_out2_layer1 = tf.keras.layers.Dropout(rate=0.2)\n",
        "\n",
        "prediction_layer1 = tf.keras.layers.Dense(2)\n",
        "\n",
        "global_average_layer1 = tf.keras.layers.GlobalAveragePooling2D()\n",
        "\n",
        "inputs_s1 = tf.keras.Input(shape=(224, 224, 3))\n",
        "x_s1 = data_augmentation(inputs_s1)\n",
        "x_s1 = tf.keras.applications.mobilenet_v2.preprocess_input(x_s1)\n",
        "#x_s1 = tf.keras.applications.resnet_v2.preprocess_input(x_s1)\n",
        "x_s1 = base_model_student1(x_s1)\n",
        "x_s1 = global_average_layer1(x_s1)\n",
        "x_s1 = drop_out1_layer1(x_s1)\n",
        "x_s1 = dense1_layer1(x_s1)\n",
        "x_s1 = drop_out2_layer1(x_s1)\n",
        "\n",
        "outputs_s1 = prediction_layer1(x_s1)\n",
        "student_model = tf.keras.Model(inputs_s1, outputs_s1)\n",
        "student_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPUcf_6jAE42",
        "outputId": "8ec37e80-7884-44ee-c20d-4765dfbfea03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:62: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class_accuracy: 64.26%\n",
            "Epoch 2: Class_accuracy: 64.78%\n",
            "Epoch 3: Class_accuracy: 62.16%\n",
            "Epoch 4: Class_accuracy: 66.14%\n",
            "Epoch 5: Class_accuracy: 60.80%\n",
            "Epoch 6: Class_accuracy: 64.36%\n",
            "Epoch 7: Class_accuracy: 63.00%\n",
            "Epoch 8: Class_accuracy: 64.15%\n",
            "Epoch 9: Class_accuracy: 63.00%\n",
            "Epoch 10: Class_accuracy: 62.89%\n"
          ]
        }
      ],
      "source": [
        "train_and_evaluate(student_model, compute_student_loss_new,epochs=10,lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUxfIHwZAaJR",
        "outputId": "44675b98-f7e6-4a42-eb3c-0fce6ffa6f24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of layers in the base model:  190\n",
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_16 (InputLayer)       [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " sequential (Sequential)     (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " tf.math.truediv_7 (TFOpLamb  (None, 224, 224, 3)      0         \n",
            " da)                                                             \n",
            "                                                                 \n",
            " tf.math.subtract_7 (TFOpLam  (None, 224, 224, 3)      0         \n",
            " bda)                                                            \n",
            "                                                                 \n",
            " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " global_average_pooling2d_7   (None, 1280)             0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 64)                81984     \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,340,098\n",
            "Trainable params: 2,305,986\n",
            "Non-trainable params: 34,112\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "base_model_student1.trainable = True\n",
        "\n",
        "# Let's take a look to see how many layers are in the base model\n",
        "print(\"Number of layers in the base model: \", len(base_model_teacher.layers))\n",
        "\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 0\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in base_model_student1.layers[:fine_tune_at]:\n",
        "  layer.trainable =  False\n",
        "student_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Js5NhZoAaJV",
        "outputId": "634009ae-7c69-42c4-d3ea-bd08fb6a7703"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:62: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class_accuracy: 64.57%\n",
            "Epoch 2: Class_accuracy: 69.71%\n",
            "Epoch 3: Class_accuracy: 74.00%\n",
            "Epoch 4: Class_accuracy: 71.49%\n",
            "Epoch 5: Class_accuracy: 74.00%\n",
            "Epoch 6: Class_accuracy: 75.89%\n",
            "Epoch 7: Class_accuracy: 76.42%\n",
            "Epoch 8: Class_accuracy: 77.92%\n",
            "Epoch 9: Class_accuracy: 78.09%\n",
            "Epoch 10: Class_accuracy: 77.36%\n",
            "Epoch 11: Class_accuracy: 76.21%\n",
            "Epoch 12: Class_accuracy: 77.67%\n",
            "Epoch 13: Class_accuracy: 80.61%\n",
            "Epoch 14: Class_accuracy: 80.50%\n",
            "Epoch 15: Class_accuracy: 81.76%\n",
            "Epoch 16: Class_accuracy: 78.72%\n",
            "Epoch 17: Class_accuracy: 75.58%\n",
            "Epoch 18: Class_accuracy: 77.57%\n",
            "Epoch 19: Class_accuracy: 79.77%\n",
            "Epoch 20: Class_accuracy: 78.83%\n",
            "Epoch 21: Class_accuracy: 79.87%\n",
            "Epoch 22: Class_accuracy: 78.93%\n",
            "Epoch 23: Class_accuracy: 79.66%\n",
            "Epoch 24: Class_accuracy: 78.09%\n",
            "Epoch 25: Class_accuracy: 80.71%\n"
          ]
        }
      ],
      "source": [
        "train_and_evaluate(student_model, compute_student_loss_new,epochs=25,lr=1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMcmsshCP6R5"
      },
      "source": [
        "AUC student state of art"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puVcxVEqPUbL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e35adda-70f8-4d63-e554-f6437cefe00e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc\n",
            "0.7438476\n"
          ]
        }
      ],
      "source": [
        "\n",
        "auc = tf.keras.metrics.AUC(from_logits=True)\n",
        "auc.reset_state()\n",
        "\n",
        "\n",
        "for batch in range(TEST_BATCHES_NUM):\n",
        "  images, labels = test_generator.next()\n",
        "  # your code start from here for step 4\n",
        "\n",
        "  label_together = np.array(compute_num_correct(student_model, images, labels))\n",
        "  label_real = np.array(label_together[2],float)\n",
        "  label_pred = np.array(label_together[1],float)\n",
        "  auc.update_state(label_real,label_pred)\n",
        "print(\"auc\")\n",
        "print(auc.result().numpy())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}